{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Document Augmentation RAG with Question Generation\n",
    "\n",
    "This notebook implements an enhanced RAG approach using document augmentation through question generation. By generating relevant questions for each text chunk, we improve the retrieval process, leading to better responses from the language model.\n",
    "\n",
    "In this implementation, we follow these steps:\n",
    "\n",
    "1. **Data Ingestion**: Extract text from a PDF file.\n",
    "2. **Chunking**: Split the text into manageable chunks.\n",
    "3. **Question Generation**: Generate relevant questions for each chunk.\n",
    "4. **Embedding Creation**: Create embeddings for both chunks and generated questions.\n",
    "5. **Vector Store Creation**: Build a simple vector store using NumPy.\n",
    "6. **Semantic Search**: Retrieve relevant chunks and questions for user queries.\n",
    "7. **Response Generation**: Generate answers based on retrieved content.\n",
    "8. **Evaluation**: Assess the quality of the generated responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Environment\n",
    "We begin by importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Text from a PDF File\n",
    "To implement RAG, we first need a source of textual data. In this case, we extract text from a PDF file using the PyMuPDF library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file and prints the first `num_chars` characters.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    # Open the PDF file\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # Initialize an empty string to store the extracted text\n",
    "\n",
    "    # Iterate through each page in the PDF\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # Get the page\n",
    "        text = page.get_text(\"text\")  # Extract text from the page\n",
    "        all_text += text  # Append the extracted text to the all_text string\n",
    "\n",
    "    return all_text  # Return the extracted text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking the Extracted Text\n",
    "Once we have the extracted text, we divide it into smaller, overlapping chunks to improve retrieval accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    Chunks the given text into segments of n characters with overlap.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to be chunked.\n",
    "    n (int): The number of characters in each chunk.\n",
    "    overlap (int): The number of overlapping characters between chunks.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of text chunks.\n",
    "    \"\"\"\n",
    "    chunks = []  # Initialize an empty list to store the chunks\n",
    "    \n",
    "    # Loop through the text with a step size of (n - overlap)\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        # Append a chunk of text from index i to i + n to the chunks list\n",
    "        chunks.append(text[i:i + n])\n",
    "\n",
    "    return chunks  # Return the list of text chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the OpenAI API Client\n",
    "We initialize the OpenAI client to generate embeddings and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://api.openai.com/v1\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Questions for Text Chunks\n",
    "This is the key enhancement over simple RAG. We generate questions that could be answered by each text chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(text_chunk, num_questions=5, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Generates relevant questions that can be answered from the given text chunk.\n",
    "\n",
    "    Args:\n",
    "    text_chunk (str): The text chunk to generate questions from.\n",
    "    num_questions (int): Number of questions to generate.\n",
    "    model (str): The model to use for question generation.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: List of generated questions.\n",
    "    \"\"\"\n",
    "    # Define the system prompt to guide the AI's behavior\n",
    "    system_prompt = \"You are an expert at generating relevant questions from text. Create concise questions that can be answered using only the provided text. Focus on key information and concepts.\"\n",
    "    \n",
    "    # Define the user prompt with the text chunk and the number of questions to generate\n",
    "    user_prompt = f\"\"\"\n",
    "    Based on the following text, generate {num_questions} different questions that can be answered using only this text:\n",
    "\n",
    "    {text_chunk}\n",
    "    \n",
    "    Format your response as a numbered list of questions only, with no additional text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate questions using the OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0.7,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract and clean questions from the response\n",
    "    questions_text = response.choices[0].message.content.strip()\n",
    "    questions = []\n",
    "    \n",
    "    # Extract questions using regex pattern matching\n",
    "    for line in questions_text.split('\\n'):\n",
    "        # Remove numbering and clean up whitespace\n",
    "        cleaned_line = re.sub(r'^\\d+\\.\\s*', '', line.strip())\n",
    "        if cleaned_line and cleaned_line.endswith('?'):\n",
    "            questions.append(cleaned_line)\n",
    "    \n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embeddings for Text\n",
    "We generate embeddings for both text chunks and generated questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    Creates embeddings for the given text using the specified OpenAI model.\n",
    "\n",
    "    Args:\n",
    "    text (str): The input text for which embeddings are to be created.\n",
    "    model (str): The model to be used for creating embeddings.\n",
    "\n",
    "    Returns:\n",
    "    dict: The response from the OpenAI API containing the embeddings.\n",
    "    \"\"\"\n",
    "    # Create embeddings for the input text using the specified model\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    return response  # Return the response containing the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Simple Vector Store\n",
    "We'll implement a simple vector store using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    A simple vector store implementation using NumPy.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the vector store.\n",
    "        \"\"\"\n",
    "        self.vectors = []\n",
    "        self.texts = []\n",
    "        self.metadata = []\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        Add an item to the vector store.\n",
    "\n",
    "        Args:\n",
    "        text (str): The original text.\n",
    "        embedding (List[float]): The embedding vector.\n",
    "        metadata (dict, optional): Additional metadata.\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))\n",
    "        self.texts.append(text)\n",
    "        self.metadata.append(metadata or {})\n",
    "    \n",
    "    def similarity_search(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        Find the most similar items to a query embedding.\n",
    "\n",
    "        Args:\n",
    "        query_embedding (List[float]): Query embedding vector.\n",
    "        k (int): Number of results to return.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict]: Top k most similar items with their texts and metadata.\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "        \n",
    "        # Convert query embedding to numpy array\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "        # Calculate similarities using cosine similarity\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity))\n",
    "        \n",
    "        # Sort by similarity (descending)\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return top k results\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],\n",
    "                \"metadata\": self.metadata[idx],\n",
    "                \"similarity\": score\n",
    "            })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Documents with Question Augmentation\n",
    "Now we'll put everything together to process documents, generate questions, and build our augmented vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200, questions_per_chunk=5):\n",
    "    \"\"\"\n",
    "    Process a document with question augmentation.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): Path to the PDF file.\n",
    "    chunk_size (int): Size of each text chunk in characters.\n",
    "    chunk_overlap (int): Overlap between chunks in characters.\n",
    "    questions_per_chunk (int): Number of questions to generate per chunk.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[List[str], SimpleVectorStore]: Text chunks and vector store.\n",
    "    \"\"\"\n",
    "    print(\"Extracting text from PDF...\")\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    print(\"Chunking text...\")\n",
    "    text_chunks = chunk_text(extracted_text, chunk_size, chunk_overlap)\n",
    "    print(f\"Created {len(text_chunks)} text chunks\")\n",
    "    \n",
    "    vector_store = SimpleVectorStore()\n",
    "    \n",
    "    print(\"Processing chunks and generating questions...\")\n",
    "    for i, chunk in enumerate(tqdm(text_chunks, desc=\"Processing Chunks\")):\n",
    "        # Create embedding for the chunk itself\n",
    "        chunk_embedding_response = create_embeddings(chunk)\n",
    "        chunk_embedding = chunk_embedding_response.data[0].embedding\n",
    "        \n",
    "        # Add the chunk to the vector store\n",
    "        vector_store.add_item(\n",
    "            text=chunk,\n",
    "            embedding=chunk_embedding,\n",
    "            metadata={\"type\": \"chunk\", \"index\": i}\n",
    "        )\n",
    "        \n",
    "        # Generate questions for this chunk\n",
    "        questions = generate_questions(chunk, num_questions=questions_per_chunk)\n",
    "        \n",
    "        # Create embeddings for each question and add to vector store\n",
    "        for j, question in enumerate(questions):\n",
    "            question_embedding_response = create_embeddings(question)\n",
    "            question_embedding = question_embedding_response.data[0].embedding\n",
    "            \n",
    "            # Add the question to the vector store\n",
    "            vector_store.add_item(\n",
    "                text=question,\n",
    "                embedding=question_embedding,\n",
    "                metadata={\"type\": \"question\", \"chunk_index\": i, \"original_chunk\": chunk}\n",
    "            )\n",
    "    \n",
    "    return text_chunks, vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Processing the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Chunking text...\n",
      "Created 42 text chunks\n",
      "Processing chunks and generating questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Chunks: 100%|██████████| 42/42 [02:04<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store contains 167 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the PDF file\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "# Process the document (extract text, create chunks, generate questions, build vector store)\n",
    "text_chunks, vector_store = process_document(\n",
    "    pdf_path, \n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=200, \n",
    "    questions_per_chunk=3\n",
    ")\n",
    "\n",
    "print(f\"Vector store contains {len(vector_store.texts)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Semantic Search\n",
    "We implement a semantic search function similar to the simple RAG implementation but adapted to our augmented vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, vector_store, k=5):\n",
    "    \"\"\"\n",
    "    Performs semantic search using the query and vector store.\n",
    "\n",
    "    Args:\n",
    "    query (str): The search query.\n",
    "    vector_store (SimpleVectorStore): The vector store to search in.\n",
    "    k (int): Number of results to return.\n",
    "\n",
    "    Returns:\n",
    "    List[Dict]: Top k most relevant items.\n",
    "    \"\"\"\n",
    "    # Create embedding for the query\n",
    "    query_embedding_response = create_embeddings(query)\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    \n",
    "    # Search the vector store\n",
    "    results = vector_store.similarity_search(query_embedding, k=k)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Query on the Augmented Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is 'Explainable AI' and why is it considered important?\n",
      "\n",
      "Search Results:\n",
      "\n",
      "Relevant Document Chunks:\n",
      "\n",
      "Matched Questions:\n",
      "Question 1 (similarity: 0.7815):\n",
      "Why are transparency and explainability important in AI systems?\n",
      "From chunk 36\n",
      "=====================================\n",
      "Question 2 (similarity: 0.7428):\n",
      "What is the aim of Explainable AI (XAI)?\n",
      "From chunk 10\n",
      "=====================================\n",
      "Question 3 (similarity: 0.7295):\n",
      "What is the focus of research in Explainable AI (XAI)?\n",
      "From chunk 29\n",
      "=====================================\n",
      "Question 4 (similarity: 0.6941):\n",
      "What do Explainable AI (XAI) techniques aim to achieve regarding AI decisions?\n",
      "From chunk 37\n",
      "=====================================\n",
      "Question 5 (similarity: 0.6869):\n",
      "What challenges are associated with the transparency and explainability of AI systems?\n",
      "From chunk 9\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# Load the validation data from a JSON file\n",
    "with open('data/val.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the first query from the validation data\n",
    "query = data[0]['question']\n",
    "\n",
    "# Perform semantic search to find relevant content\n",
    "search_results = semantic_search(query, vector_store, k=5)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nSearch Results:\")\n",
    "\n",
    "# Organize results by type\n",
    "chunk_results = []\n",
    "question_results = []\n",
    "\n",
    "for result in search_results:\n",
    "    if result[\"metadata\"][\"type\"] == \"chunk\":\n",
    "        chunk_results.append(result)\n",
    "    else:\n",
    "        question_results.append(result)\n",
    "\n",
    "# Print chunk results first\n",
    "print(\"\\nRelevant Document Chunks:\")\n",
    "for i, result in enumerate(chunk_results):\n",
    "    print(f\"Context {i + 1} (similarity: {result['similarity']:.4f}):\")\n",
    "    print(result[\"text\"][:300] + \"...\")\n",
    "    print(\"=====================================\")\n",
    "\n",
    "# Then print question matches\n",
    "print(\"\\nMatched Questions:\")\n",
    "for i, result in enumerate(question_results):\n",
    "    print(f\"Question {i + 1} (similarity: {result['similarity']:.4f}):\")\n",
    "    print(result[\"text\"])\n",
    "    chunk_idx = result[\"metadata\"][\"chunk_index\"]\n",
    "    print(f\"From chunk {chunk_idx}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Context for Response\n",
    "Now we prepare the context by combining information from relevant chunks and questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_context(search_results):\n",
    "    \"\"\"\n",
    "    Prepares a unified context from search results for response generation.\n",
    "\n",
    "    Args:\n",
    "    search_results (List[Dict]): Results from semantic search.\n",
    "\n",
    "    Returns:\n",
    "    str: Combined context string.\n",
    "    \"\"\"\n",
    "    # Extract unique chunks referenced in the results\n",
    "    chunk_indices = set()\n",
    "    context_chunks = []\n",
    "    \n",
    "    # First add direct chunk matches\n",
    "    for result in search_results:\n",
    "        if result[\"metadata\"][\"type\"] == \"chunk\":\n",
    "            chunk_indices.add(result[\"metadata\"][\"index\"])\n",
    "            context_chunks.append(f\"Chunk {result['metadata']['index']}:\\n{result['text']}\")\n",
    "    \n",
    "    # Then add chunks referenced by questions\n",
    "    for result in search_results:\n",
    "        if result[\"metadata\"][\"type\"] == \"question\":\n",
    "            chunk_idx = result[\"metadata\"][\"chunk_index\"]\n",
    "            if chunk_idx not in chunk_indices:\n",
    "                chunk_indices.add(chunk_idx)\n",
    "                context_chunks.append(f\"Chunk {chunk_idx} (referenced by question '{result['text']}'):\\n{result['metadata']['original_chunk']}\")\n",
    "    \n",
    "    # Combine all context chunks\n",
    "    full_context = \"\\n\\n\".join(context_chunks)\n",
    "    return full_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Response Based on Retrieved Chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Generates a response based on the query and context.\n",
    "\n",
    "    Args:\n",
    "    query (str): User's question.\n",
    "    context (str): Context information retrieved from the vector store.\n",
    "    model (str): Model to use for response generation.\n",
    "\n",
    "    Returns:\n",
    "    str: Generated response.\n",
    "    \"\"\"\n",
    "    system_prompt = \"You are an AI assistant that strictly answers based on the given context. If the answer cannot be derived directly from the provided context, respond with: 'I do not have enough information to answer that.'\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Please answer the question based only on the context provided above. Be concise and accurate.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and Displaying the Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is 'Explainable AI' and why is it considered important?\n",
      "\n",
      "Response:\n",
      "Explainable AI (XAI) aims to make AI systems more transparent and understandable. It is considered important because it enhances trust and accountability by providing insights into how AI models make decisions, enabling users to assess their fairness and accuracy.\n"
     ]
    }
   ],
   "source": [
    "# Prepare context from search results\n",
    "context = prepare_context(search_results)\n",
    "\n",
    "# Generate response\n",
    "response_text = generate_response(query, context)\n",
    "\n",
    "print(\"\\nQuery:\", query)\n",
    "print(\"\\nResponse:\")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 36 (referenced by question 'Why are transparency and explainability important in AI systems?'):\n",
      "nt aligns with societal values. Education and awareness campaigns inform the public \n",
      "about AI, its impacts, and its potential. \n",
      "Chapter 19: AI and Ethics \n",
      "Principles of Ethical AI \n",
      "Ethical AI principles guide the development and deployment of AI systems to ensure they are fair, \n",
      "transparent, accountable, and beneficial to society. Key principles include respect for human \n",
      "rights, privacy, non-discrimination, and beneficence. \n",
      " \n",
      " \n",
      "Addressing Bias in AI \n",
      "AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair \n",
      "or discriminatory outcomes. Addressing bias requires careful data collection, algorithm design, \n",
      "and ongoing monitoring and evaluation. \n",
      "Transparency and Explainability \n",
      "Transparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) \n",
      "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
      "fairness and accuracy. \n",
      "Privacy and Data Protection \n",
      "AI systems often rely on la\n",
      "\n",
      "Chunk 10 (referenced by question 'What is the aim of Explainable AI (XAI)?'):\n",
      "control, accountability, and the \n",
      "potential for unintended consequences. Establishing clear guidelines and ethical frameworks for \n",
      "AI development and deployment is crucial. \n",
      "Weaponization of AI \n",
      "The potential use of AI in autonomous weapons systems raises significant ethical and security \n",
      "concerns. International discussions and regulations are needed to address the risks associated \n",
      "with AI-powered weapons. \n",
      "Chapter 5: The Future of Artificial Intelligence \n",
      "The future of AI is likely to be characterized by continued advancements and broader adoption \n",
      "across various domains. Key trends and areas of development include: \n",
      "Explainable AI (XAI) \n",
      "Explainable AI (XAI) aims to make AI systems more transparent and understandable. XAI \n",
      "techniques are being developed to provide insights into how AI models make decisions, \n",
      "enhancing trust and accountability. \n",
      "AI at the Edge \n",
      "AI at the edge involves processing data locally on devices, rather than relying on cloud-based \n",
      "servers. This approach reduc\n",
      "\n",
      "Chunk 29 (referenced by question 'What is the focus of research in Explainable AI (XAI)?'):\n",
      " incidents. \n",
      "Environmental Monitoring \n",
      "AI-powered environmental monitoring systems track air and water quality, detect pollution, and \n",
      "support environmental protection efforts. These systems provide real-time data, identify \n",
      "pollution sources, and inform environmental policies. \n",
      "Chapter 15: The Future of AI Research \n",
      "Advancements in Deep Learning \n",
      "Continued advancements in deep learning are expected to drive further breakthroughs in AI. \n",
      "Research is focused on developing more efficient and interpretable deep learning models, as well \n",
      "as exploring new architectures and training techniques. \n",
      "Explainable AI (XAI) \n",
      "Explainable AI (XAI) aims to make AI systems more transparent and understandable. Research in \n",
      "XAI focuses on developing methods for explaining AI decisions, enhancing trust, and improving \n",
      "accountability. \n",
      "AI and Neuroscience \n",
      "The intersection of AI and neuroscience is a promising area of research. Understanding the \n",
      "human brain can inspire new AI algorithms and architectures, \n",
      "\n",
      "Chunk 37 (referenced by question 'What do Explainable AI (XAI) techniques aim to achieve regarding AI decisions?'):\n",
      "systems. Explainable AI (XAI) \n",
      "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
      "fairness and accuracy. \n",
      "Privacy and Data Protection \n",
      "AI systems often rely on large amounts of data, raising concerns about privacy and data \n",
      "protection. Ensuring responsible data handling, implementing privacy-preserving techniques, \n",
      "and complying with data protection regulations are crucial. \n",
      "Accountability and Responsibility \n",
      "Establishing accountability and responsibility for AI systems is essential for addressing potential \n",
      "harms and ensuring ethical behavior. This includes defining roles and responsibilities for \n",
      "developers, deployers, and users of AI systems. \n",
      "Chapter 20: Building Trust in AI \n",
      "Transparency and Explainability \n",
      "Transparency and explainability are key to building trust in AI. Making AI systems understandable \n",
      "and providing insights into their decision-making processes helps users assess their reliability \n",
      "and fairness. \n",
      "Robustness and Reliability \n",
      "\n",
      "\n",
      "Chunk 9 (referenced by question 'What challenges are associated with the transparency and explainability of AI systems?'):\n",
      "inability \n",
      "Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to \n",
      "understand how they arrive at their decisions. Enhancing transparency and explainability is \n",
      "crucial for building trust and accountability. \n",
      " \n",
      " \n",
      "Privacy and Security \n",
      "AI systems often rely on large amounts of data, raising concerns about privacy and data security. \n",
      "Protecting sensitive information and ensuring responsible data handling are essential. \n",
      "Job Displacement \n",
      "The automation capabilities of AI have raised concerns about job displacement, particularly in \n",
      "industries with repetitive or routine tasks. Addressing the potential economic and social impacts \n",
      "of AI-driven automation is a key challenge. \n",
      "Autonomy and Control \n",
      "As AI systems become more autonomous, questions arise about control, accountability, and the \n",
      "potential for unintended consequences. Establishing clear guidelines and ethical frameworks for \n",
      "AI development and deployment is crucial. \n",
      "Weaponization of AI \n",
      "The p\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the AI Response\n",
    "We compare the AI response with the expected answer and assign a score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response from Simple Rag\n",
    "Explainable AI (XAI) aims to make AI systems more transparent and understandable, providing insights into how AI models make decisions. It is considered important because it enhances trust and accountability, allowing users to assess the fairness and accuracy of AI decisions.\n",
    "\n",
    "\n",
    "## Response from Simple Rag + Semantic Chunking\n",
    "Explainable AI (XAI) aims to make AI systems more transparent and understandable by developing methods for explaining AI decisions. It is considered important because it enhances trust in AI systems and improves accountability, allowing users to assess the fairness and accuracy of AI decisions.\n",
    "\n",
    "## Response from Simple Rag + Semantic Chunking + Sizing\n",
    "128\n",
    "Explainable AI (XAI) aims to make AI systems more transparent and understandable. It is considered important because transparency and explainability are essential for building trust in AI systems, as they help users understand the decisions made by these systems.\n",
    "\n",
    "\n",
    "256\n",
    "Explainable AI (XAI) aims to make AI systems more transparent and understandable. It focuses on developing techniques that provide insights into how AI models make decisions, which enhances trust and accountability. Transparency and explainability are essential for building trust in AI systems, enabling users to assess the fairness and accuracy of AI decisions.\n",
    "\n",
    "512\n",
    "Explainable AI (XAI) aims to make AI systems more transparent and understandable. It focuses on developing methods for explaining AI decisions, which enhances trust and accountability. XAI is considered important because it enables users to assess the fairness and accuracy of AI decisions, thereby building trust in AI systems.\n",
    "\n",
    "## Response from Context enrichment rag\n",
    "Explainable AI (XAI) refers to techniques that aim to make AI decisions more understandable, enabling users to assess their fairness and accuracy. It is considered important because transparency and explainability are essential for building trust in AI systems, allowing users to understand the decision-making processes behind AI outcomes.\n",
    "\n",
    "## Response from headers enrichment rag\n",
    "Explainable AI (XAI) refers to techniques that aim to make AI decisions more understandable, enabling users to assess their fairness and accuracy. It is considered important because it enhances transparency and trust in AI systems, allowing users to better understand the decision-making processes and evaluate the reliability and fairness of those systems.\n",
    "\n",
    "\n",
    "## Response from RAG + Augmented questions\n",
    "Explainable AI (XAI) aims to make AI systems more transparent and understandable. It is considered important because it enhances trust and accountability by providing insights into how AI models make decisions, enabling users to assess their fairness and accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
